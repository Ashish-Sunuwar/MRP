{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xguCR-zVcdj",
        "outputId": "4050c652-e1db-4849-b321-72580d3b44ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYttQqvCVjeh",
        "outputId": "510d2d89-f59e-4a8f-cec2-8f72022c32a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 3294804 | Val: 639385 | Test: 570805\n",
            "Epoch 1/20\n",
            "3218/3218 - 144s - 45ms/step - accuracy: 0.5111 - loss: 0.6931 - val_accuracy: 0.4907 - val_loss: 0.6941\n",
            "Epoch 2/20\n",
            "3218/3218 - 133s - 41ms/step - accuracy: 0.5149 - loss: 0.6926 - val_accuracy: 0.4952 - val_loss: 0.6936\n",
            "Epoch 3/20\n",
            "3218/3218 - 133s - 41ms/step - accuracy: 0.5162 - loss: 0.6924 - val_accuracy: 0.4964 - val_loss: 0.6940\n",
            "Epoch 4/20\n",
            "3218/3218 - 133s - 41ms/step - accuracy: 0.5191 - loss: 0.6919 - val_accuracy: 0.5042 - val_loss: 0.6942\n",
            "Epoch 5/20\n",
            "3218/3218 - 133s - 41ms/step - accuracy: 0.5245 - loss: 0.6896 - val_accuracy: 0.5056 - val_loss: 0.6936\n",
            "\u001b[1m3218/3218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 15ms/step\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step\n",
            "\u001b[1m558/558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[200]\tvalid_0's auc: 0.819544\tvalid_0's binary_logloss: 0.523058\n",
            "Optimal τ on VAL: 0.34 (F1=0.7409)\n",
            "\n",
            "2023 Test Performance:\n",
            "  Accuracy   : 0.7280\n",
            "  Precision  : 0.6854\n",
            "  Recall     : 0.8508\n",
            "  F1 Score   : 0.7592\n",
            "  ROC AUC    : 0.8234\n",
            "  Confusion Matrix:\n",
            "[[170810 112315]\n",
            " [ 42933 244747]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv1D, Bidirectional, LSTM, GRU,\n",
        "    Dropout, Dense, Concatenate\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import lightgbm as lgb\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix\n",
        ")\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "# Reproducibility & Load Data\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "df = pd.read_csv(\n",
        "    \"/content/drive/MyDrive/MRP/final_dataset.csv\",\n",
        "    parse_dates=[\"date\"]\n",
        ")\n",
        "df.sort_values([\"symbol\", \"date\"], inplace=True, ignore_index=True)\n",
        "\n",
        "# Feature Engineering\n",
        "# multi-lag returns\n",
        "for lag in (1, 3, 5):\n",
        "    df[f\"return_1d_lag{lag}\"] = df.groupby(\"symbol\")[\"return_1d\"].shift(lag)\n",
        "\n",
        "# 7-day rolling on returns\n",
        "df[\"return_7d_mean\"] = df.groupby(\"symbol\")[\"return_1d\"]\\\n",
        "                        .transform(lambda x: x.rolling(7).mean())\n",
        "df[\"return_7d_std\"]  = df.groupby(\"symbol\")[\"return_1d\"]\\\n",
        "                        .transform(lambda x: x.rolling(7).std())\n",
        "\n",
        "# drop any rows with NA from shifts/rolling\n",
        "df.dropna(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Define feature lists\n",
        "price_feats = [\n",
        "    \"adj close\",\"log_volume\",\"ma_10\",\"vol_30\",\"rsi_14\",\n",
        "    \"return_1d_lag1\",\"return_1d_lag3\",\"return_1d_lag5\",\n",
        "    \"return_7d_mean\",\"return_7d_std\"\n",
        "]\n",
        "# static_feats now only the same price_feats\n",
        "static_feats = price_feats.copy()\n",
        "\n",
        "TARGET  = \"target\"\n",
        "SEQ_LEN = 60\n",
        "\n",
        "# Build sequences & static arrays\n",
        "Xs, stat_X, ys, dates = [], [], [], []\n",
        "for sym, grp in df.groupby(\"symbol\"):\n",
        "    grp = grp.sort_values(\"date\", ignore_index=True)\n",
        "    seq_vals  = grp[price_feats].values\n",
        "    stat_vals = grp[static_feats].values\n",
        "    lbls      = grp[TARGET].values\n",
        "    dts       = grp[\"date\"].values\n",
        "\n",
        "    for i in range(SEQ_LEN, len(grp)):\n",
        "        Xs.append(seq_vals[i-SEQ_LEN : i])\n",
        "        stat_X.append(stat_vals[i])\n",
        "        ys.append(lbls[i])\n",
        "        dates.append(dts[i])\n",
        "\n",
        "X        = np.stack(Xs).astype(\"float32\")       # (N, SEQ_LEN, 10)\n",
        "static_X = np.stack(stat_X).astype(\"float32\")  # (N, 10)\n",
        "y        = np.array(ys, dtype=\"float32\")\n",
        "dates    = np.array(dates)\n",
        "\n",
        "# Chronological Train/Val/Test split\n",
        "train_mask = dates <= np.datetime64(\"2021-12-31\")\n",
        "val_mask   = (dates >  np.datetime64(\"2021-12-31\")) & (dates <= np.datetime64(\"2022-12-31\"))\n",
        "test_mask  = dates >  np.datetime64(\"2022-12-31\")\n",
        "\n",
        "X_tr, X_va, X_te = X[train_mask], X[val_mask], X[test_mask]\n",
        "s_tr, s_va, s_te = static_X[train_mask], static_X[val_mask], static_X[test_mask]\n",
        "y_tr, y_va, y_te = y[train_mask], y[val_mask], y[test_mask]\n",
        "\n",
        "print(f\"Train: {len(y_tr)} | Val: {len(y_va)} | Test: {len(y_te)}\")\n",
        "\n",
        "# Train CNN–BiLSTM–GRU with multi-kernel & dilated convs\n",
        "inp = Input(shape=(SEQ_LEN, len(price_feats)))\n",
        "# three parallel convs\n",
        "c1 = Conv1D(32, 3, padding=\"same\", activation=\"relu\")(inp)\n",
        "c2 = Conv1D(32, 5, padding=\"same\", activation=\"relu\")(inp)\n",
        "c3 = Conv1D(32, 3, dilation_rate=2, padding=\"same\", activation=\"relu\")(inp)\n",
        "x  = Concatenate()([c1, c2, c3])\n",
        "x  = Conv1D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "x  = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "x  = GRU(32)(x)\n",
        "emb = Dropout(0.2)(x)\n",
        "out = Dense(1, activation=\"sigmoid\")(emb)\n",
        "\n",
        "seq_model = Model(inputs=inp, outputs=out)\n",
        "seq_model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=Adam(learning_rate=1e-3),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "seq_model.fit(\n",
        "    X_tr, y_tr,\n",
        "    validation_data=(X_va, y_va),\n",
        "    epochs=20,\n",
        "    batch_size=1024,\n",
        "    callbacks=[EarlyStopping(\"val_loss\", patience=3, restore_best_weights=True)],\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Extract embeddings\n",
        "embed_model = Model(inputs=inp, outputs=emb)\n",
        "emb_tr = embed_model.predict(X_tr, batch_size=1024)\n",
        "emb_va = embed_model.predict(X_va, batch_size=1024)\n",
        "emb_te = embed_model.predict(X_te, batch_size=1024)\n",
        "\n",
        "# Train LightGBM on [embeddings ∥ static_feats]\n",
        "train_feat = np.hstack([emb_tr, s_tr])\n",
        "val_feat   = np.hstack([emb_va, s_va])\n",
        "test_feat  = np.hstack([emb_te, s_te])\n",
        "\n",
        "clf = lgb.LGBMClassifier(\n",
        "    n_estimators   = 200,\n",
        "    learning_rate  = 0.05,\n",
        "    num_leaves     = 31,\n",
        "    random_state   = SEED,\n",
        "    n_jobs         = -1,\n",
        "    verbosity      = -1\n",
        ")\n",
        "clf.fit(\n",
        "    train_feat, y_tr,\n",
        "    eval_set=[(val_feat, y_va)],\n",
        "    eval_metric=\"auc\",\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=10)]\n",
        ")\n",
        "\n",
        "# Calibration\n",
        "calibrator = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=\"prefit\")\n",
        "calibrator.fit(val_feat, y_va)\n",
        "\n",
        "# Threshold sweep on calibrated validation scores\n",
        "val_probs, best_t, best_f1 = calibrator.predict_proba(val_feat)[:,1], 0.5, 0\n",
        "for t in np.linspace(0.3,0.7,41):\n",
        "    p = (val_probs >= t).astype(int)\n",
        "    f = f1_score(y_va, p)\n",
        "    if f > best_f1:\n",
        "        best_f1, best_t = f, t\n",
        "print(f\"Optimal τ on VAL: {best_t:.2f} (F1={best_f1:.4f})\")\n",
        "\n",
        "# Final evaluation on test set\n",
        "test_probs = calibrator.predict_proba(test_feat)[:,1]\n",
        "test_pred  = (test_probs >= best_t).astype(int)\n",
        "\n",
        "print(\"\\n2023 Test Performance:\")\n",
        "print(f\"  Accuracy   : {accuracy_score(y_te, test_pred):.4f}\")\n",
        "print(f\"  Precision  : {precision_score(y_te, test_pred):.4f}\")\n",
        "print(f\"  Recall     : {recall_score(y_te, test_pred):.4f}\")\n",
        "print(f\"  F1 Score   : {f1_score(y_te, test_pred):.4f}\")\n",
        "print(f\"  ROC AUC    : {roc_auc_score(y_te, test_probs):.4f}\")\n",
        "print(\"  Confusion Matrix:\")\n",
        "print(confusion_matrix(y_te, test_pred))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
