{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BP-gT8lKU_9f",
        "outputId": "49287a3f-b3e4-4b4a-bd2d-427eaa2ecfe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, Bidirectional, LSTM, GRU, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix, brier_score_loss\n",
        ")\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "# Reproducibility & Load Data\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/MRP/final_dataset.csv\", parse_dates=[\"date\"])\n",
        "df = df.sort_values([\"symbol\", \"date\"]).reset_index(drop=True)\n",
        "\n",
        "# Feature Engineering\n",
        "for lag in (1, 3, 5):\n",
        "    df[f\"return_1d_lag{lag}\"] = df.groupby(\"symbol\")[\"return_1d\"].shift(lag)\n",
        "\n",
        "df[\"return_7d_mean\"] = df.groupby(\"symbol\")[\"return_1d\"].transform(lambda x: x.rolling(7).mean())\n",
        "df[\"return_7d_std\"]  = df.groupby(\"symbol\")[\"return_1d\"].transform(lambda x: x.rolling(7).std())\n",
        "\n",
        "df[\"sentiment_7d_mean\"] = df.groupby(\"symbol\")[\"avg_sentiment\"].transform(lambda x: x.rolling(7).mean())\n",
        "df[\"pos_sent_count_7d\"] = df.groupby(\"symbol\")[\"avg_sentiment\"] \\\n",
        "    .transform(lambda x: x.rolling(7).apply(lambda a: (a > 0).sum(), raw=True))\n",
        "df[\"neg_sent_count_7d\"] = df.groupby(\"symbol\")[\"avg_sentiment\"] \\\n",
        "    .transform(lambda x: x.rolling(7).apply(lambda a: (a < 0).sum(), raw=True))\n",
        "\n",
        "dow_ohe = pd.get_dummies(df[\"day_of_week\"], prefix=\"dow\", drop_first=True)\n",
        "df = pd.concat([df, dow_ohe], axis=1)\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Build Sequence & Static Arrays\n",
        "price_feats = [\"adj close\",\"log_volume\",\"ma_10\",\"vol_30\",\"rsi_14\",\"return_1d_lag1\"]\n",
        "news_feats  = [\"avg_sentiment\",\"avg_sentiment_confidence\",\"sentiment_std_7\"]\n",
        "eng_feats   = [\n",
        "    \"return_1d_lag3\",\"return_1d_lag5\",\n",
        "    \"return_7d_mean\",\"return_7d_std\",\n",
        "    \"sentiment_7d_mean\",\"pos_sent_count_7d\",\"neg_sent_count_7d\"\n",
        "]\n",
        "dow_feats   = [c for c in df.columns if c.startswith(\"dow_\")]\n",
        "static_feats = price_feats + news_feats + eng_feats + dow_feats\n",
        "\n",
        "SEQ_LEN = 30\n",
        "Xs, stat_X, ys, dates = [], [], [], []\n",
        "\n",
        "for sym, grp in df.groupby(\"symbol\"):\n",
        "    grp = grp.sort_values(\"date\").reset_index(drop=True)\n",
        "    seq_vals  = grp[price_feats].values\n",
        "    stat_vals = grp[static_feats].values\n",
        "    lbls      = grp[\"target\"].values\n",
        "    dts       = grp[\"date\"].values\n",
        "\n",
        "    for i in range(SEQ_LEN, len(grp)):\n",
        "        Xs.append(seq_vals[i-SEQ_LEN:i])\n",
        "        stat_X.append(stat_vals[i])\n",
        "        ys.append(lbls[i])\n",
        "        dates.append(dts[i])\n",
        "\n",
        "X        = np.stack(Xs).astype(\"float32\")\n",
        "static_X = np.stack(stat_X).astype(\"float32\")\n",
        "y        = np.array(ys, dtype=\"float32\")\n",
        "dates    = np.array(dates)\n",
        "\n",
        "# Chronological Train / Val / Test Split\n",
        "train_mask = dates <= np.datetime64(\"2021-12-31\")\n",
        "val_mask   = (dates >  np.datetime64(\"2021-12-31\")) & (dates <= np.datetime64(\"2022-12-31\"))\n",
        "test_mask  = dates >  np.datetime64(\"2022-12-31\")\n",
        "\n",
        "X_train, X_val, X_test = X[train_mask], X[val_mask], X[test_mask]\n",
        "s_train, s_val, s_test = static_X[train_mask], static_X[val_mask], static_X[test_mask]\n",
        "y_train, y_val, y_test = y[train_mask], y[val_mask], y[test_mask]\n",
        "\n",
        "print(f\"Train: {len(y_train)} | Val: {len(y_val)} | Test: {len(y_test)}\")\n",
        "\n",
        "# Train CNN–BiLSTM–GRU Embedding Model\n",
        "inp = Input(shape=(SEQ_LEN, X_train.shape[2]))\n",
        "x   = Conv1D(32, 3, padding=\"same\", activation=\"relu\")(inp)\n",
        "x   = Conv1D(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "x   = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "x   = GRU(32)(x)\n",
        "embed = Dropout(0.2)(x)\n",
        "out   = Dense(1, activation=\"sigmoid\")(embed)\n",
        "\n",
        "seq_model = Model(inputs=inp, outputs=out)\n",
        "seq_model.compile(\n",
        "    optimizer=Adam(1e-3),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "seq_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=1024,\n",
        "    callbacks=[EarlyStopping(\"val_loss\", patience=3, restore_best_weights=True)],\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Extract Embeddings\n",
        "embed_model = Model(inputs=inp, outputs=embed)\n",
        "emb_train   = embed_model.predict(X_train, batch_size=1024)\n",
        "emb_val     = embed_model.predict(X_val,   batch_size=1024)\n",
        "emb_test    = embed_model.predict(X_test,  batch_size=1024)\n",
        "\n",
        "# Train LightGBM on Hybrid Features\n",
        "train_feat = np.hstack([emb_train, s_train])\n",
        "val_feat   = np.hstack([emb_val,   s_val])\n",
        "test_feat  = np.hstack([emb_test,  s_test])\n",
        "\n",
        "clf = lgb.LGBMClassifier(\n",
        "    n_estimators=200,\n",
        "    num_leaves=127,\n",
        "    min_data_in_leaf=20,\n",
        "    learning_rate=0.01,\n",
        "    random_state=SEED,\n",
        "    n_jobs=-1,\n",
        "    verbosity=-1\n",
        ")\n",
        "\n",
        "# use the 2022 validation set for early stopping\n",
        "clf.fit(\n",
        "    train_feat, y_train,\n",
        "    eval_set=[(val_feat, y_val)],\n",
        "    eval_metric=\"binary_logloss\",\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(period=0)]\n",
        ")\n",
        "\n",
        "# Final Evaluation on 2023 Test Set\n",
        "y_prob = clf.predict_proba(test_feat)[:, 1]\n",
        "y_pred = (y_prob >= 0.35).astype(int)\n",
        "\n",
        "print(\"\\nFinal 2023 Test Performance:\")\n",
        "print(f\"  Accuracy    : {accuracy_score(y_test,   y_pred):.4f}\")\n",
        "print(f\"  Precision   : {precision_score(y_test,  y_pred):.4f}\")\n",
        "print(f\"  Recall      : {recall_score(y_test,     y_pred):.4f}\")\n",
        "print(f\"  F1 Score    : {f1_score(y_test,         y_pred):.4f}\")\n",
        "print(f\"  ROC AUC     : {roc_auc_score(y_test, y_prob):.4f}\")\n",
        "print(f\"  Brier Score : {brier_score_loss(y_test, y_prob):.4f}\")\n",
        "print(\"  Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxftFFDoVAlS",
        "outputId": "15b2ec28-a9a4-430b-b555-c076ebda084b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 3451220 | Val: 641865 | Test: 571382\n",
            "Epoch 1/20\n",
            "3371/3371 - 70s - 21ms/step - accuracy: 0.5124 - loss: 0.6929 - val_accuracy: 0.4873 - val_loss: 0.6945\n",
            "Epoch 2/20\n",
            "3371/3371 - 65s - 19ms/step - accuracy: 0.5161 - loss: 0.6924 - val_accuracy: 0.4930 - val_loss: 0.6945\n",
            "Epoch 3/20\n",
            "3371/3371 - 65s - 19ms/step - accuracy: 0.5187 - loss: 0.6919 - val_accuracy: 0.4947 - val_loss: 0.6948\n",
            "Epoch 4/20\n",
            "3371/3371 - 65s - 19ms/step - accuracy: 0.5231 - loss: 0.6902 - val_accuracy: 0.4954 - val_loss: 0.6955\n",
            "\u001b[1m3371/3371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step\n",
            "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n",
            "\u001b[1m558/558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[200]\tvalid_0's binary_logloss: 0.556131\n",
            "\n",
            "Final 2023 Test Performance:\n",
            "  Accuracy    : 0.6826\n",
            "  Precision   : 0.6274\n",
            "  Recall      : 0.9120\n",
            "  F1 Score    : 0.7434\n",
            "  ROC AUC     : 0.8090\n",
            "  Brier Score : 0.1843\n",
            "  Confusion Matrix:\n",
            "[[127337 155998]\n",
            " [ 25337 262710]]\n"
          ]
        }
      ]
    }
  ]
}
