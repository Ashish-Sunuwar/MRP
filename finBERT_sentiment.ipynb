{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu7gmJxUn2Mz",
        "outputId": "e07c9e5a-2871-49c9-9d9d-20448aa67097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "CSV file successfully read:\n",
            "         date stock_symbol                                   combined_summary\n",
            "0  2011-01-03           AA  Aluminum producer Alcoa Inc. ( AA ) on Monday ...\n",
            "1  2011-01-03          BHP  The downside of medium-sized vessels (as compa...\n",
            "2  2011-01-03          BTU  When translated into dollars and cents, Califo...\n",
            "3  2011-01-03          CLF  Also charging out of the gates in 2011 are com...\n",
            "4  2011-01-03          CLX  Cleaning products maker The Clorox Company ( C...\n",
            "CSV file successfully read:\n",
            "         date       open       high        low      close  adj close  \\\n",
            "0  2011-01-03  29.728184  30.143061  29.620888  29.957081  27.344431   \n",
            "1  2011-01-04  30.035765  30.114449  29.456366  29.678112  27.089796   \n",
            "2  2011-01-05  29.513592  29.849785  29.327610  29.613733  27.031036   \n",
            "3  2011-01-06  29.592276  29.928469  29.477825  29.670958  27.083261   \n",
            "4  2011-01-07  29.699572  29.899857  29.356224  29.771101  27.174671   \n",
            "\n",
            "      volume ticker  year  month  day    weekday  \n",
            "0  4994000.0      A  2011      1    3     Monday  \n",
            "1  5017200.0      A  2011      1    4    Tuesday  \n",
            "2  4519000.0      A  2011      1    5  Wednesday  \n",
            "3  4699000.0      A  2011      1    6   Thursday  \n",
            "4  3810900.0      A  2011      1    7     Friday  \n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "file_path1 = '/content/drive/MyDrive/MRP/stock_news.csv'\n",
        "file_path2 = '/content/drive/MyDrive/MRP/stock_price.csv'\n",
        "try:\n",
        "  news_df = pd.read_csv(file_path1)\n",
        "  print(\"CSV file successfully read:\")\n",
        "  print(news_df.head())\n",
        "\n",
        "  price_df = pd.read_csv(file_path2)\n",
        "  print(\"CSV file successfully read:\")\n",
        "  print(price_df.head())\n",
        "\n",
        "except FileNotFoundError:\n",
        "  print(f\"Error: File not found: {e}\")\n",
        "except Exception as e:\n",
        "  print (f\"An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers tqdm --quiet\n"
      ],
      "metadata": {
        "id": "xVXUZBZzoMYv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "cqwAxOj2pIOa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"yiyanghkust/finbert-tone\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOlG30GOpO78",
        "outputId": "1863fee5-f00f-4a5e-8c53-2d69e535d3cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finbert = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    truncation=True,\n",
        "    max_length=512,\n",
        "    padding=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLZ9nzSopVI1",
        "outputId": "cc0897cc-a47c-4cae-8536-23e94eafeff4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment(texts):\n",
        "    results = finbert(texts)\n",
        "    return [(r['label'], r['score']) for r in results]\n",
        "\n",
        "sentiments = []\n",
        "batch_size = 32\n",
        "summaries = news_df['combined_summary'].tolist()\n",
        "\n",
        "for i in tqdm(range(0, len(summaries), batch_size), desc=\"Running FinBERT\"):\n",
        "    batch = summaries[i:i+batch_size]\n",
        "    try:\n",
        "        batch_results = get_sentiment(batch)\n",
        "        sentiments.extend(batch_results)\n",
        "    except Exception as e:\n",
        "        print(f\"Error at batch {i}: {e}\")\n",
        "        sentiments.extend([('neutral', 0.0)] * len(batch))  # fallback if failed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wMRzTaGre2g",
        "outputId": "bcda38cf-9859-41c3-cfb0-7047ce67b847"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running FinBERT:   0%|          | 10/36666 [00:04<4:07:50,  2.46it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "Running FinBERT: 100%|██████████| 36666/36666 [5:12:39<00:00,  1.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_df[['sentiment_label', 'sentiment_score']] = pd.DataFrame(sentiments, index=news_df.index)\n"
      ],
      "metadata": {
        "id": "pDdybqcxre5F"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_df.to_csv('/content/drive/MyDrive/MRP/stock_news_with_sentiment.csv', index=False)\n",
        "print(\"Sentiment analysis complete. File saved as stock_news_with_sentiment.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM0oTgPvrfKN",
        "outputId": "5fb898ee-7abc-4cd4-9f50-5f407bc7203e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment analysis complete. File saved as stock_news_with_sentiment.csv\n"
          ]
        }
      ]
    }
  ]
}